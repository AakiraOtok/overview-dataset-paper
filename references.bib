@ARTICLE{LeNet,
	author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	journal={Proceedings of the IEEE}, 
	title={Gradient-based learning applied to document recognition}, 
	year={1998},
	volume={86},
	number={11},
	pages={2278-2324},
	keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
	doi={10.1109/5.726791}}
	
@article{AlexNet,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	title = {ImageNet classification with deep convolutional neural networks},
	year = {2017},
	issue_date = {June 2017},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {60},
	number = {6},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/3065386},
	doi = {10.1145/3065386},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
	journal = {Commun. ACM},
	month = {may},
	pages = {84–90},
	numpages = {7}
}

@article{ILSVRC,
	Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
	Title = {{ImageNet Large Scale Visual Recognition Challenge}},
	Year = {2015},
	journal   = {International Journal of Computer Vision (IJCV)},
	doi = {10.1007/s11263-015-0816-y},
	volume={115},
	number={3},
	pages={211-252}
}

@INPROCEEDINGS{KTH,
	author={Schuldt, C. and Laptev, I. and Caputo, B.},
	booktitle={Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.}, 
	title={Recognizing human actions: a local SVM approach}, 
	year={2004},
	volume={3},
	number={},
	pages={32-36 Vol.3},
	keywords={Humans;Support vector machines;Computer vision;Pattern recognition;Support vector machine classification;Cameras;Frequency;Spatial databases;Performance evaluation;Image recognition},
	doi={10.1109/ICPR.2004.1334462}
}

@INPROCEEDINGS{Weizmann,
	author={Blank, M. and Gorelick, L. and Shechtman, E. and Irani, M. and Basri, R.},
	booktitle={Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1}, 
	title={Actions as space-time shapes}, 
	year={2005},
	volume={2},
	number={},
	pages={1395-1402 Vol. 2},
	keywords={Shape;Humans;Video sequences;Torso;Poisson equations;Computer vision;Information analysis;Optical computing;Image motion analysis;Motion analysis},
	doi={10.1109/ICCV.2005.28}
}

@INPROCEEDINGS{IXMAS,
	author={Weinland, Daniel and Boyer, Edmond and Ronfard, Remi},
	booktitle={2007 IEEE 11th International Conference on Computer Vision}, 
	title={Action Recognition from Arbitrary Views using 3D Exemplars}, 
	year={2007},
	volume={},
	number={},
	pages={1-7},
	keywords={Cameras;Hidden Markov models;Humans;Image recognition;Image reconstruction;Solid modeling;Layout;Parametric statistics;Kinematics;Image motion analysis},
	doi={10.1109/ICCV.2007.4408849}
}

@INPROCEEDINGS{HollyWood,
	author={Laptev, Ivan and Marszalek, Marcin and Schmid, Cordelia and Rozenfeld, Benjamin},
	booktitle={2008 IEEE Conference on Computer Vision and Pattern Recognition}, 
	title={Learning realistic human actions from movies}, 
	year={2008},
	volume={},
	number={},
	pages={1-8},
	keywords={Humans;Motion pictures;Image recognition;Video sharing;Layout;Text categorization;Object recognition;Robustness;Clothing;Cameras},
	doi={10.1109/CVPR.2008.4587756}
}

@INPROCEEDINGS{UCFSports,
	author={Rodriguez, Mikel D. and Ahmed, Javed and Shah, Mubarak},
	booktitle={2008 IEEE Conference on Computer Vision and Pattern Recognition}, 
	title={Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition}, 
	year={2008},
	volume={},
	number={},
	pages={1-8},
	keywords={Humans;Image motion analysis;Data analysis;Fourier transforms;Optical films;Optical filters;Computer vision;Spatiotemporal phenomena;Frequency domain analysis;Computational efficiency},
	doi={10.1109/CVPR.2008.4587727}
}

@INPROCEEDINGS{Hollywood2,
	author={Marszalek, Marcin and Laptev, Ivan and Schmid, Cordelia},
	booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
	title={Actions in context}, 
	year={2009},
	volume={},
	number={},
	pages={2929-2936},
	keywords={Layout;Motion pictures;Humans;Roads;Surveillance;Text mining;Testing;Support vector machines;Support vector machine classification;Scalability},
	doi={10.1109/CVPR.2009.5206557}
}

@INPROCEEDINGS{UCFYouTube,
	author={Liu, Jingen and Jiebo Luo and Shah, Mubarak},
	booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
	title={Recognizing realistic actions from videos “in the wild”}, 
	year={2009},
	volume={},
	number={},
	pages={1996-2003},
	keywords={Videos;Cameras;YouTube;Humans;Feature extraction;Motion pictures;Shape;Spatiotemporal phenomena;Computer vision;Vocabulary},
	doi={10.1109/CVPR.2009.5206744}
}

@InProceedings{Olympic,
	author="Niebles, Juan Carlos
	and Chen, Chih-Wei
	and Fei-Fei, Li",
	editor="Daniilidis, Kostas
	and Maragos, Petros
	and Paragios, Nikos",
	title="Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification",
	booktitle="Computer Vision -- ECCV 2010",
	year="2010",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="392--405",
	abstract="Much recent research in human activity recognition has focused on the problem of recognizing simple repetitive (walking, running, waving) and punctual actions (sitting up, opening a door, hugging). However, many interesting human activities are characterized by a complex temporal composition of simple actions. Automatic recognition of such complex actions can benefit from a good understanding of the temporal structures. We present in this paper a framework for modeling motion by exploiting the temporal structure of the human activities. In our framework, we represent activities as temporal compositions of motion segments. We train a discriminative model that encodes a temporal decomposition of video sequences, and appearance models for each motion segment. In recognition, a query video is matched to the model according to the learned appearances and motion segment decomposition. Classification is made based on the quality of matching between the motion segment classifiers and the temporal segments in the query sequence. To validate our approach, we introduce a new dataset of complex Olympic Sports activities. We show that our algorithm performs better than other state of the art methods.",
	isbn="978-3-642-15552-9"
}

@INPROCEEDINGS{HMDB51,
	author={Kuehne, H. and Jhuang, H. and Garrote, E. and Poggio, T. and Serre, T.},
	booktitle={2011 International Conference on Computer Vision}, 
	title={HMDB: A large video database for human motion recognition}, 
	year={2011},
	volume={},
	number={},
	pages={2556-2563},
	keywords={Cameras;YouTube;Databases;Training;Visualization;Humans;Motion pictures},
	doi={10.1109/ICCV.2011.6126543}
}

@misc{UCF101,
	title={UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild}, 
	author={Khurram Soomro and Amir Roshan Zamir and Mubarak Shah},
	year={2012},
	eprint={1212.0402},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@article{PASCALVOC,
	author = {Everingham, Mark and Van Gool, Luc and Williams, Christopher and Winn, John and Zisserman, Andrew},
	year = {2010},
	month = {06},
	pages = {303-338},
	title = {The Pascal Visual Object Classes (VOC) challenge},
	volume = {88},
	journal = {International Journal of Computer Vision},
	doi = {10.1007/s11263-009-0275-4}
}

@misc{AVA,
	title={AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions}, 
	author={Chunhui Gu and Chen Sun and David A. Ross and Carl Vondrick and Caroline Pantofaru and Yeqing Li and Sudheendra Vijayanarasimhan and George Toderici and Susanna Ricco and Rahul Sukthankar and Cordelia Schmid and Jitendra Malik},
	year={2018},
	eprint={1705.08421},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@inproceedings{Sports1M,
	title     = {Large-scale Video Classification with Convolutional Neural Networks},
	author    = {Andrej Karpathy and George Toderici and Sanketh Shetty and Thomas Leung and Rahul Sukthankar and Li Fei-Fei},
	year      = {2014},
	booktitle = {CVPR}
}

@misc{YouTube8M,
	title={YouTube-8M: A Large-Scale Video Classification Benchmark}, 
	author={Sami Abu-El-Haija and Nisarg Kothari and Joonseok Lee and Paul Natsev and George Toderici and Balakrishnan Varadarajan and Sudheendra Vijayanarasimhan},
	year={2016},
	eprint={1609.08675},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{somethingsomething,
	title={The "something something" video database for learning and evaluating visual common sense},
	author={Raghav Goyal and Samira Ebrahimi Kahou and Vincent Michalski and Joanna Materzyńska and Susanne Westphal and Heuna Kim and Valentin Haenel and Ingo Fruend and Peter Yianilos and Moritz Mueller-Freitag and Florian Hoppe and Christian Thurau and Ingo Bax and Roland Memisevic},
	year={2017},
	eprint={1706.04261},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{momentsintime,
	title={Moments in Time Dataset: one million videos for event understanding}, 
	author={Mathew Monfort and Alex Andonian and Bolei Zhou and Kandan Ramakrishnan and Sarah Adel Bargal and Tom Yan and Lisa Brown and Quanfu Fan and Dan Gutfruend and Carl Vondrick and Aude Oliva},
	year={2019},
	eprint={1801.03150},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@INPROCEEDINGS{ActivityNet,
	author={Heilbron, Fabian Caba and Escorcia, Victor and Ghanem, Bernard and Niebles, Juan Carlos},
	booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	title={ActivityNet: A large-scale video benchmark for human activity understanding}, 
	year={2015},
	volume={},
	number={},
	pages={961-970},
	keywords={Benchmark testing;Taxonomy;Cleaning;Semantics;Organizations;Complexity theory;YouTube},
	doi={10.1109/CVPR.2015.7298698}
}

@article{THUMOS,
	title={The THUMOS challenge on action recognition for videos “in the wild”},
	volume={155},
	ISSN={1077-3142},
	url={http://dx.doi.org/10.1016/j.cviu.2016.10.018},
	DOI={10.1016/j.cviu.2016.10.018},
	journal={Computer Vision and Image Understanding},
	publisher={Elsevier BV},
	author={Idrees, Haroon and Zamir, Amir R. and Jiang, Yu-Gang and Gorban, Alex and Laptev, Ivan and Sukthankar, Rahul and Shah, Mubarak},
	year={2017},
	month=feb, pages={1–23} 
}

@misc{Charades,
	title={Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding}, 
	author={Gunnar A. Sigurdsson and Gül Varol and Xiaolong Wang and Ali Farhadi and Ivan Laptev and Abhinav Gupta},
	year={2016},
	eprint={1604.01753},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{faster-rcnn,
	title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 
	author={Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun},
	year={2016},
	eprint={1506.01497},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{personembedding,
	title={PersonNet: Person Re-identification with Deep Convolutional Neural Networks}, 
	author={Lin Wu and Chunhua Shen and Anton van den Hengel},
	year={2016},
	eprint={1601.07255},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@article{TheHungarian,
	title={The Hungarian method for the assignment problem},
	author={Harold W. Kuhn},
	journal={Naval Research Logistics (NRL)},
	year={1955},
	volume={52},
	url={https://api.semanticscholar.org/CorpusID:9426884}
}

@inproceedings{activitynetchallenge,
	title={ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding},
	author={Fabian Caba Heilbron, Victor Escorcia, Bernard Ghanem and Juan Carlos Niebles},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={961--970},
	year={2015}
}
<<<<<<< HEAD

@misc{HACS,
	title={HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization}, 
	author={Hang Zhao and Antonio Torralba and Lorenzo Torresani and Zhicheng Yan},
	year={2019},
	eprint={1712.09374},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{HVU,
	title={Large Scale Holistic Video Understanding}, 
	author={Ali Diba and Mohsen Fayyaz and Vivek Sharma and Manohar Paluri and Jurgen Gall and Rainer Stiefelhagen and Luc Van Gool},
	year={2020},
	eprint={1904.11451},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{AViD,
	title={AViD Dataset: Anonymized Videos from Diverse Countries}, 
	author={AJ Piergiovanni and Michael S. Ryoo},
	year={2020},
	eprint={2007.05515},
=======
@article{Somethingv2,
	Author = { Farzaneh Mahdisoltani and David Fleet Guillaume Berger and Waseem Gharbieh and Roland Memisevici},
	Title = {{On the effectiveness of task granularity for transfer learning}},
	Year = {2018},
	eprint={1804.09235},
>>>>>>> a1c09371185157a5eee447f3d08c77467ff983df
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
